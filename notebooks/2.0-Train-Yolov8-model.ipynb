{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yolov8 Model Training\n",
    "\n",
    "This notebook helps easily train a yolo model. Model evaluation will happen in another notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports and variable setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mreag/repos/DBD-Killer-AI/notebooks\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Import all libraries\n",
    "import os\n",
    "from roboflow import Roboflow\n",
    "from IPython import display\n",
    "import ultralytics\n",
    "from ultralytics import YOLO\n",
    "from IPython.display import display, Image\n",
    "from pathlib import Path\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "import sys\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "# Setup HOME environment variable\n",
    "HOME = os.getcwd()\n",
    "print(HOME)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    Device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    Device = torch.device(\"mps\")\n",
    "else:\n",
    "    Device = torch.device(\"cpu\")\n",
    "print(Device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.238 ðŸš€ Python-3.10.13 torch-2.4.1 CPU (Apple M1 Pro)\n",
      "Setup complete âœ… (8 CPUs, 16.0 GB RAM, 306.4/460.4 GB disk)\n"
     ]
    }
   ],
   "source": [
    "# Check image displays are good\n",
    "# display.clear_output()\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "# Check ultralytics library is good\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment variables\n",
    "PROJECT_DIR = Path.cwd().parent\n",
    "DATASET_VERSION = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import Model\n",
    "\n",
    "Pre-trained is the ideal model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    }
   ],
   "source": [
    "model = YOLO(model=str(PROJECT_DIR) + \"/models/yolov8n.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/mreagles524/Documents/gitrepos/projects/DBD-Killer-AI/data/external'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(PROJECT_DIR) + \"/data/external\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "Dependency ultralytics==8.0.196 is required but found version=8.0.238, to fix: `pip install ultralytics==8.0.196`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in /Users/mreagles524/Documents/gitrepos/projects/DBD-Killer-AI/data/external/deadbydaylightkillerai/killer_ai_object_detection/8 to yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 116415/116415 [00:02<00:00, 51651.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to /Users/mreagles524/Documents/gitrepos/projects/DBD-Killer-AI/data/external/deadbydaylightkillerai/killer_ai_object_detection/8 in yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5702/5702 [00:00<00:00, 9339.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.36 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.238 ðŸš€ Python-3.10.13 torch-2.4.1 MPS (Apple M1 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=/Users/mreagles524/Documents/gitrepos/projects/DBD-Killer-AI/models/yolov8n.pt, data=/Users/mreagles524/Documents/gitrepos/projects/DBD-Killer-AI/data/external/deadbydaylightkillerai/killer_ai_object_detection/8/data.yaml, epochs=10, time=None, patience=50, batch=16, imgsz=800, save=True, save_period=-1, cache=False, device=mps, workers=0, project=None, name=train5, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    752482  ultralytics.nn.modules.head.Detect           [6, [64, 128, 256]]           \n",
      "Model summary: 225 layers, 3012018 parameters, 3012002 gradients\n",
      "\n",
      "Transferred 355/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/mreagles524/Documents/gitrepos/projects/DBD-Killer-AI/data/external/deadbydaylightkillerai/killer_ai_object_detection/8/train/labels.cache... 2488 images, 593 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2488/2488 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/mreagles524/Documents/gitrepos/projects/DBD-Killer-AI/data/external/deadbydaylightkillerai/killer_ai_object_detection/8/valid/labels.cache... 238 images, 58 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 238/238 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/detect/train5/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10         0G       1.57       5.04      1.374         11        800: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 156/156 [03:50<00:00,  1.48s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/8 [00:08<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Couldn't load custom C++ ops. This can happen if your PyTorch and torchvision versions are incompatible, or if you had errors while compiling torchvision from source. For further information on the compatible versions, check https://github.com/pytorch/vision#installation for the compatibility matrix. Please check your PyTorch version with torch.__version__ and your torchvision version with torchvision.__version__ and verify if they are compatible, and if not please reinstall torchvision so that it matches your PyTorch install.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/mreagles524/Documents/gitrepos/projects/DBD-Killer-AI/notebooks/2.0-Train-Yolov8-model.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mreagles524/Documents/gitrepos/projects/DBD-Killer-AI/notebooks/2.0-Train-Yolov8-model.ipynb#X12sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m# Get location of yml\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mreagles524/Documents/gitrepos/projects/DBD-Killer-AI/notebooks/2.0-Train-Yolov8-model.ipynb#X12sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m yml_location \u001b[39m=\u001b[39m data_location\u001b[39m.\u001b[39mlocation \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/data.yaml\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/mreagles524/Documents/gitrepos/projects/DBD-Killer-AI/notebooks/2.0-Train-Yolov8-model.ipynb#X12sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m model, results_train \u001b[39m=\u001b[39m train_yolo(yolo_model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mreagles524/Documents/gitrepos/projects/DBD-Killer-AI/notebooks/2.0-Train-Yolov8-model.ipynb#X12sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m                                     data_yml\u001b[39m=\u001b[39;49myml_location,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mreagles524/Documents/gitrepos/projects/DBD-Killer-AI/notebooks/2.0-Train-Yolov8-model.ipynb#X12sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m                                     epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mreagles524/Documents/gitrepos/projects/DBD-Killer-AI/notebooks/2.0-Train-Yolov8-model.ipynb#X12sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m                                     imgsz\u001b[39m=\u001b[39;49m\u001b[39m800\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mreagles524/Documents/gitrepos/projects/DBD-Killer-AI/notebooks/2.0-Train-Yolov8-model.ipynb#X12sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m                                     plots\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mreagles524/Documents/gitrepos/projects/DBD-Killer-AI/notebooks/2.0-Train-Yolov8-model.ipynb#X12sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m                                     workers\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mreagles524/Documents/gitrepos/projects/DBD-Killer-AI/notebooks/2.0-Train-Yolov8-model.ipynb#X12sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m                                     device\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mmps\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/Documents/gitrepos/projects/DBD-Killer-AI/dbdkillerai/models/train_model.py:12\u001b[0m, in \u001b[0;36mtrain_yolo\u001b[0;34m(yolo_model, data_yml, epochs, imgsz, plots, workers, device)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain_yolo\u001b[39m(yolo_model: YOLO, data_yml: \u001b[39mstr\u001b[39m, epochs: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m150\u001b[39m, imgsz: \u001b[39mint\u001b[39m\u001b[39m=\u001b[39m\u001b[39m800\u001b[39m,\n\u001b[1;32m      7\u001b[0m                plots: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m, workers: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m, device: Any \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m):\n\u001b[1;32m      8\u001b[0m     \u001b[39m# Create a new YOLO model from scratch\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     \u001b[39m# model = YOLO(model=yolo_model)\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \n\u001b[1;32m     11\u001b[0m     \u001b[39m# Train the model using the dataset for all loaded parameters\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m     results_train \u001b[39m=\u001b[39m yolo_model\u001b[39m.\u001b[39;49mtrain(data\u001b[39m=\u001b[39;49mdata_yml,\n\u001b[1;32m     13\u001b[0m                         epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[1;32m     14\u001b[0m                         imgsz\u001b[39m=\u001b[39;49mimgsz,\n\u001b[1;32m     15\u001b[0m                         plots\u001b[39m=\u001b[39;49mplots,\n\u001b[1;32m     16\u001b[0m                         workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[1;32m     17\u001b[0m                         device\u001b[39m=\u001b[39;49mdevice)\n\u001b[1;32m     19\u001b[0m     \u001b[39mreturn\u001b[39;00m yolo_model, results_train\n",
      "File \u001b[0;32m~/anaconda3/envs/dbd_ai/lib/python3.10/site-packages/ultralytics/engine/model.py:356\u001b[0m, in \u001b[0;36mModel.train\u001b[0;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mmodel\n\u001b[1;32m    355\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mhub_session \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msession  \u001b[39m# attach optional HUB session\u001b[39;00m\n\u001b[0;32m--> 356\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer\u001b[39m.\u001b[39;49mtrain()\n\u001b[1;32m    357\u001b[0m \u001b[39m# Update model and cfg after training\u001b[39;00m\n\u001b[1;32m    358\u001b[0m \u001b[39mif\u001b[39;00m RANK \u001b[39min\u001b[39;00m (\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/envs/dbd_ai/lib/python3.10/site-packages/ultralytics/engine/trainer.py:189\u001b[0m, in \u001b[0;36mBaseTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    186\u001b[0m         ddp_cleanup(\u001b[39mself\u001b[39m, \u001b[39mstr\u001b[39m(file))\n\u001b[1;32m    188\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 189\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_train(world_size)\n",
      "File \u001b[0;32m~/anaconda3/envs/dbd_ai/lib/python3.10/site-packages/ultralytics/engine/trainer.py:392\u001b[0m, in \u001b[0;36mBaseTrainer._do_train\u001b[0;34m(self, world_size)\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[39m# Validation\u001b[39;00m\n\u001b[1;32m    391\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mval \u001b[39mor\u001b[39;00m final_epoch \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstopper\u001b[39m.\u001b[39mpossible_stop \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstop:\n\u001b[0;32m--> 392\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetrics, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfitness \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvalidate()\n\u001b[1;32m    393\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave_metrics(metrics\u001b[39m=\u001b[39m{\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlabel_loss_items(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtloss), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetrics, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlr})\n\u001b[1;32m    394\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstop \u001b[39m|\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstopper(epoch \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfitness)\n",
      "File \u001b[0;32m~/anaconda3/envs/dbd_ai/lib/python3.10/site-packages/ultralytics/engine/trainer.py:507\u001b[0m, in \u001b[0;36mBaseTrainer.validate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    501\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvalidate\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    502\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    503\u001b[0m \u001b[39m    Runs validation on test set using self.validator.\u001b[39;00m\n\u001b[1;32m    504\u001b[0m \n\u001b[1;32m    505\u001b[0m \u001b[39m    The returned dict is expected to contain \"fitness\" key.\u001b[39;00m\n\u001b[1;32m    506\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 507\u001b[0m     metrics \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvalidator(\u001b[39mself\u001b[39;49m)\n\u001b[1;32m    508\u001b[0m     fitness \u001b[39m=\u001b[39m metrics\u001b[39m.\u001b[39mpop(\u001b[39m'\u001b[39m\u001b[39mfitness\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m-\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy())  \u001b[39m# use loss as fitness measure if not found\u001b[39;00m\n\u001b[1;32m    509\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbest_fitness \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbest_fitness \u001b[39m<\u001b[39m fitness:\n",
      "File \u001b[0;32m~/anaconda3/envs/dbd_ai/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/dbd_ai/lib/python3.10/site-packages/ultralytics/engine/validator.py:178\u001b[0m, in \u001b[0;36mBaseValidator.__call__\u001b[0;34m(self, trainer, model)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[39m# Postprocess\u001b[39;00m\n\u001b[1;32m    177\u001b[0m \u001b[39mwith\u001b[39;00m dt[\u001b[39m3\u001b[39m]:\n\u001b[0;32m--> 178\u001b[0m     preds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpostprocess(preds)\n\u001b[1;32m    180\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupdate_metrics(preds, batch)\n\u001b[1;32m    181\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mplots \u001b[39mand\u001b[39;00m batch_i \u001b[39m<\u001b[39m \u001b[39m3\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/dbd_ai/lib/python3.10/site-packages/ultralytics/models/yolo/detect/val.py:81\u001b[0m, in \u001b[0;36mDetectionValidator.postprocess\u001b[0;34m(self, preds)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpostprocess\u001b[39m(\u001b[39mself\u001b[39m, preds):\n\u001b[1;32m     80\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Apply Non-maximum suppression to prediction outputs.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 81\u001b[0m     \u001b[39mreturn\u001b[39;00m ops\u001b[39m.\u001b[39;49mnon_max_suppression(preds,\n\u001b[1;32m     82\u001b[0m                                    \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs\u001b[39m.\u001b[39;49mconf,\n\u001b[1;32m     83\u001b[0m                                    \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs\u001b[39m.\u001b[39;49miou,\n\u001b[1;32m     84\u001b[0m                                    labels\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlb,\n\u001b[1;32m     85\u001b[0m                                    multi_label\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     86\u001b[0m                                    agnostic\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs\u001b[39m.\u001b[39;49msingle_cls,\n\u001b[1;32m     87\u001b[0m                                    max_det\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs\u001b[39m.\u001b[39;49mmax_det)\n",
      "File \u001b[0;32m~/anaconda3/envs/dbd_ai/lib/python3.10/site-packages/ultralytics/utils/ops.py:270\u001b[0m, in \u001b[0;36mnon_max_suppression\u001b[0;34m(prediction, conf_thres, iou_thres, classes, agnostic, multi_label, labels, max_det, nc, max_time_img, max_nms, max_wh, rotated)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    269\u001b[0m     boxes \u001b[39m=\u001b[39m x[:, :\u001b[39m4\u001b[39m] \u001b[39m+\u001b[39m c  \u001b[39m# boxes (offset by class)\u001b[39;00m\n\u001b[0;32m--> 270\u001b[0m     i \u001b[39m=\u001b[39m torchvision\u001b[39m.\u001b[39;49mops\u001b[39m.\u001b[39;49mnms(boxes, scores, iou_thres)  \u001b[39m# NMS\u001b[39;00m\n\u001b[1;32m    271\u001b[0m i \u001b[39m=\u001b[39m i[:max_det]  \u001b[39m# limit detections\u001b[39;00m\n\u001b[1;32m    273\u001b[0m \u001b[39m# # Experimental\u001b[39;00m\n\u001b[1;32m    274\u001b[0m \u001b[39m# merge = False  # use merge-NMS\u001b[39;00m\n\u001b[1;32m    275\u001b[0m \u001b[39m# if merge and (1 < n < 3E3):  # Merge NMS (boxes merged using weighted mean)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[39m#     if redundant:\u001b[39;00m\n\u001b[1;32m    283\u001b[0m \u001b[39m#         i = i[iou.sum(1) > 1]  # require redundancy\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/dbd_ai/lib/python3.10/site-packages/torchvision/ops/boxes.py:40\u001b[0m, in \u001b[0;36mnms\u001b[0;34m(boxes, scores, iou_threshold)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39mis_scripting() \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39mis_tracing():\n\u001b[1;32m     39\u001b[0m     _log_api_usage_once(nms)\n\u001b[0;32m---> 40\u001b[0m _assert_has_ops()\n\u001b[1;32m     41\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mops\u001b[39m.\u001b[39mtorchvision\u001b[39m.\u001b[39mnms(boxes, scores, iou_threshold)\n",
      "File \u001b[0;32m~/anaconda3/envs/dbd_ai/lib/python3.10/site-packages/torchvision/extension.py:48\u001b[0m, in \u001b[0;36m_assert_has_ops\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_assert_has_ops\u001b[39m():\n\u001b[1;32m     47\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m _has_ops():\n\u001b[0;32m---> 48\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m     49\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mCouldn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt load custom C++ ops. This can happen if your PyTorch and \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     50\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mtorchvision versions are incompatible, or if you had errors while compiling \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     51\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mtorchvision from source. For further information on the compatible versions, check \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     52\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mhttps://github.com/pytorch/vision#installation for the compatibility matrix. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     53\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mPlease check your PyTorch version with torch.__version__ and your torchvision \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     54\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mversion with torchvision.__version__ and verify if they are compatible, and if not \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     55\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mplease reinstall torchvision so that it matches your PyTorch install.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     56\u001b[0m         )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Couldn't load custom C++ ops. This can happen if your PyTorch and torchvision versions are incompatible, or if you had errors while compiling torchvision from source. For further information on the compatible versions, check https://github.com/pytorch/vision#installation for the compatibility matrix. Please check your PyTorch version with torch.__version__ and your torchvision version with torchvision.__version__ and verify if they are compatible, and if not please reinstall torchvision so that it matches your PyTorch install."
     ]
    }
   ],
   "source": [
    "from dbdkillerai.data.make_dataset import roboflow_connect, roboflow_download\n",
    "from dbdkillerai.models.train_model import train_yolo, validate_yolo\n",
    "\n",
    "# Establish Roboflow connection and acquire dataset location. DONT download.\n",
    "rf_conn, rf_project = roboflow_connect()\n",
    "data_location = roboflow_download(rf_project=rf_project,\n",
    "                                  rf_data_version=DATASET_VERSION,\n",
    "                                  data_format=\"yolov8\",\n",
    "                                  project_dir=str(PROJECT_DIR) + \"/data/external\",\n",
    "                                  overwrite=True)\n",
    "\n",
    "# Get location of yml\n",
    "yml_location = data_location.location + \"/data.yaml\"\n",
    "model, results_train = train_yolo(yolo_model=model,\n",
    "                                    data_yml=yml_location,\n",
    "                                    epochs=150,\n",
    "                                    imgsz=800,\n",
    "                                    plots=True,\n",
    "                                    workers=0,\n",
    "                                    device=\"mps\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate Custom Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.227 ðŸš€ Python-3.10.13 torch-2.1.2 CUDA:0 (NVIDIA GeForce RTX 3080, 10240MiB)\n",
      "Model summary (fused): 168 layers, 3006428 parameters, 0 gradients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/mreag/repos/DBD-Killer-AI/data/external/deadbydaylightkillerai/killer_ai_object_detection/7/valid/labels.cache... 238 images, 80 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 238/238 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:02<00:00,  6.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        238        343      0.806      0.713      0.765       0.52\n",
      "              activity        238         12      0.815      0.733      0.777      0.501\n",
      "             generator        238        189      0.862      0.884      0.904      0.656\n",
      "                  hook        238        120      0.855      0.734      0.791      0.526\n",
      "              survivor        238         22      0.694        0.5      0.588      0.396\n",
      "Speed: 0.4ms preprocess, 2.8ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val5\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "best_weights_location = str(results_train.save_dir) + \"/weights/best.pt\"\n",
    "best_model = YOLO(best_weights_location)\n",
    "results_val = validate_yolo(yolo_model=best_model,\n",
    "                            data_yml=yml_location)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
